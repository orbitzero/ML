{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f2aa389",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries and packages required are loaded\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "170e5c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the horses and human dataset into data\n",
    "\n",
    "data = \"/notebooks/horse-or-human\"\n",
    "\n",
    "# The data is already split into train and test folders, so we load train folder into the object below\n",
    "training_dir = 'horse-or-human/train/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "32d283bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "  \n",
    "#Rescaling of images by 1/255\n",
    "\n",
    "    \n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "#ImageDataGenerator generates images by flowing them from the training directory\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "training_dir,target_size=(300, 300),\n",
    "class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f2820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d436ac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the images are larger (300x300 pixels), we need more layers for the network\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "      tf.keras.layers.Conv2D(16, (3,3), activation='relu' ,\n",
    "                  input_shape=(300, 300, 3)),\n",
    "      tf.keras.layers.MaxPooling2D(2, 2),\n",
    "      tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "      tf.keras.layers.MaxPooling2D(2,2),\n",
    "      tf.keras.layers.Flatten(),\n",
    "      tf.keras.layers.Dense(512, activation='relu'),\n",
    "      tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e16163f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 298, 298, 16)      448       \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 149, 149, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 147, 147, 32)      4640      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 73, 73, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 71, 71, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 35, 35, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 33, 33, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 16, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 14, 14, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 7, 7, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 3136)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               1606144   \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,704,097\n",
      "Trainable params: 1,704,097\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Summary of our model\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58e1cfc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lalithraj/opt/anaconda3/lib/python3.9/site-packages/keras/optimizers/legacy/rmsprop.py:143: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Model is trained here by compiling it with a binary crossentropy loss function (for two classes: horses and humans)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "  optimizer=tf.keras.optimizers.legacy.RMSprop(lr=2e-5),\n",
    "  metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74568927",
   "metadata": {},
   "outputs": [],
   "source": [
    "###TRAINING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2be65f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c5/yq5hwz6x591dwtqs54tvkdnw0000gn/T/ipykernel_14785/760566052.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 19:33:46.980733: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 26s 736ms/step - loss: 0.6746 - acc: 0.5453\n",
      "Epoch 2/15\n",
      "33/33 [==============================] - 24s 728ms/step - loss: 0.6368 - acc: 0.7439\n",
      "Epoch 3/15\n",
      "33/33 [==============================] - 24s 728ms/step - loss: 0.5812 - acc: 0.8500\n",
      "Epoch 4/15\n",
      "33/33 [==============================] - 25s 746ms/step - loss: 0.5113 - acc: 0.8705\n",
      "Epoch 5/15\n",
      "33/33 [==============================] - 25s 738ms/step - loss: 0.4343 - acc: 0.8978\n",
      "Epoch 6/15\n",
      "33/33 [==============================] - 25s 753ms/step - loss: 0.3598 - acc: 0.9172\n",
      "Epoch 7/15\n",
      "33/33 [==============================] - 25s 758ms/step - loss: 0.2989 - acc: 0.9279\n",
      "Epoch 8/15\n",
      "33/33 [==============================] - 25s 748ms/step - loss: 0.2454 - acc: 0.9484\n",
      "Epoch 9/15\n",
      "33/33 [==============================] - 25s 753ms/step - loss: 0.1981 - acc: 0.9669\n",
      "Epoch 10/15\n",
      "33/33 [==============================] - 25s 752ms/step - loss: 0.1621 - acc: 0.9698\n",
      "Epoch 11/15\n",
      "33/33 [==============================] - 25s 744ms/step - loss: 0.1374 - acc: 0.9796\n",
      "Epoch 12/15\n",
      "33/33 [==============================] - 25s 749ms/step - loss: 0.1155 - acc: 0.9786\n",
      "Epoch 13/15\n",
      "33/33 [==============================] - 25s 766ms/step - loss: 0.1059 - acc: 0.9737\n",
      "Epoch 14/15\n",
      "33/33 [==============================] - 26s 787ms/step - loss: 0.0886 - acc: 0.9825\n",
      "Epoch 15/15\n",
      "33/33 [==============================] - 25s 760ms/step - loss: 0.0775 - acc: 0.9834\n"
     ]
    }
   ],
   "source": [
    "# Fit generator for the model to find the accuracy\n",
    "\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      epochs=15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4c26bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Saving validation dataset into validation_dir and images are rescaled\n",
    "\n",
    "\n",
    "\n",
    "validation_dir = 'horse-or-human/validation/'\n",
    "    \n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "#Image data generator creates a flow from validation dataset\n",
    "validation_generator = train_datagen.flow_from_directory(validation_dir,target_size=(300, 300),class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85d11f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/c5/yq5hwz6x591dwtqs54tvkdnw0000gn/T/ipykernel_14785/2340640799.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 19:41:40.730171: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - ETA: 0s - loss: 0.0710 - acc: 0.9815"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 19:42:05.533906: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33/33 [==============================] - 27s 807ms/step - loss: 0.0710 - acc: 0.9815 - val_loss: 1.3031 - val_acc: 0.7656\n",
      "Epoch 2/10\n",
      "33/33 [==============================] - 26s 798ms/step - loss: 0.0626 - acc: 0.9844 - val_loss: 1.1251 - val_acc: 0.8008\n",
      "Epoch 3/10\n",
      "33/33 [==============================] - 27s 819ms/step - loss: 0.0563 - acc: 0.9893 - val_loss: 1.3869 - val_acc: 0.7773\n",
      "Epoch 4/10\n",
      "33/33 [==============================] - 27s 810ms/step - loss: 0.0545 - acc: 0.9873 - val_loss: 1.3102 - val_acc: 0.7891\n",
      "Epoch 5/10\n",
      "33/33 [==============================] - 27s 801ms/step - loss: 0.0484 - acc: 0.9873 - val_loss: 1.3736 - val_acc: 0.7891\n",
      "Epoch 6/10\n",
      "33/33 [==============================] - 27s 807ms/step - loss: 0.0464 - acc: 0.9844 - val_loss: 1.7113 - val_acc: 0.7578\n",
      "Epoch 7/10\n",
      "33/33 [==============================] - 27s 800ms/step - loss: 0.0451 - acc: 0.9864 - val_loss: 1.5236 - val_acc: 0.7891\n",
      "Epoch 8/10\n",
      "33/33 [==============================] - 27s 822ms/step - loss: 0.0384 - acc: 0.9883 - val_loss: 1.4324 - val_acc: 0.8086\n",
      "Epoch 9/10\n",
      "33/33 [==============================] - 27s 824ms/step - loss: 0.0375 - acc: 0.9883 - val_loss: 1.5993 - val_acc: 0.7930\n",
      "Epoch 10/10\n",
      "33/33 [==============================] - 28s 839ms/step - loss: 0.0328 - acc: 0.9893 - val_loss: 1.6669 - val_acc: 0.7891\n"
     ]
    }
   ],
   "source": [
    "###TESTING MODEL\n",
    "\n",
    "#Model Fit generator using 10 cycles\n",
    "    \n",
    "    history = model.fit_generator(\n",
    "      train_generator,\n",
    "      epochs=10,\n",
    "           validation_data=validation_generator\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de97cc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Conclusion:\n",
    "\n",
    "#Model is overfitting (Accuracy is higher on training set than validation set): Trainingacc: 0.9893 validationaccuracy: 0.7891\n",
    "\n",
    "#As the model is trained only on a small dataset consisting around 500 images, the accuracy seems to be low on validation set. With more data (images), model can learn better with more accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
